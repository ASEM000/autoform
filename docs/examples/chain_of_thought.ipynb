{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef7fbb6",
   "metadata": {},
   "source": [
    "# ðŸ§  Chain-of-Thought Gradients\n",
    "\n",
    "This tutorial demonstrates how `af.pullback` provides feedback on each step of a multi-step reasoning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fbd3f",
   "metadata": {},
   "source": [
    "## Setup (Colab only)\n",
    "\n",
    "Uncomment and run the following cell if running in Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autoform\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoform as af\n",
    "\n",
    "MODEL = \"openai/gpt-4o\"  # or \"ollama/llama3.2:3b\" for local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d018c",
   "metadata": {},
   "source": [
    "## 1. The Problem\n",
    "\n",
    "Complex reasoning often fails silently. When a chain-of-thought answer is wrong, which step caused it? Without visibility into intermediate steps, debugging is guesswork."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83d5c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 2. Define Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b28feb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Answer(af.Struct):\n",
    "    reasoning: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b58e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 3. Multi-Step Reasoning with Checkpoints\n",
    "\n",
    "We checkpoint each reasoning step for observability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ade7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_thought(question: str) -> Answer:\n",
    "    \"\"\"Multi-step reasoning with checkpoints at each step.\"\"\"\n",
    "\n",
    "    # Step 1: Break down the problem\n",
    "    step1_prompt = af.format(\"Break down this question into sub-problems:\\n{}\", question)\n",
    "    msgs1 = [{\"role\": \"user\", \"content\": step1_prompt}]\n",
    "    step1 = af.lm_call(msgs1, model=MODEL)\n",
    "    step1 = af.checkpoint(step1, key=\"breakdown\", collection=\"reasoning\")\n",
    "\n",
    "    # Step 2: Solve each sub-problem\n",
    "    step2_prompt = af.format(\"Given these sub-problems:\\n{}\\n\\nSolve each one:\", step1)\n",
    "    msgs2 = [{\"role\": \"user\", \"content\": step2_prompt}]\n",
    "    step2 = af.lm_call(msgs2, model=MODEL)\n",
    "    step2 = af.checkpoint(step2, key=\"solutions\", collection=\"reasoning\")\n",
    "\n",
    "    # Step 3: Synthesize final answer\n",
    "    step3_prompt = af.format(\n",
    "        \"Sub-problems:\\n{}\\n\\nSolutions:\\n{}\\n\\nProvide a final answer with reasoning:\",\n",
    "        step1,\n",
    "        step2,\n",
    "    )\n",
    "    msgs3 = [{\"role\": \"user\", \"content\": step3_prompt}]\n",
    "    return af.struct_lm_call(msgs3, model=MODEL, struct=Answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cd4ba",
   "metadata": {},
   "source": [
    "## 4. Build the IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = \"...\"\n",
    "ir = af.trace(chain_of_thought)(dummy)\n",
    "print(ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c52247",
   "metadata": {},
   "source": [
    "## 5. Run with Collect\n",
    "\n",
    "Capture intermediate reasoning steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca909099",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, captured = af.collect(ir, collection=\"reasoning\")(\"What is 15% of 80?\")\n",
    "\n",
    "print(\"Answer:\", result.answer)\n",
    "print(\"\\nCaptured steps:\", list(captured.keys()))\n",
    "print(\"\\nBreakdown:\", captured[\"breakdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e367670",
   "metadata": {},
   "source": [
    "## 6. Pullback: Get Improvement Hints\n",
    "\n",
    "Given feedback on the output, pullback suggests how to improve the **input**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_ir = af.pullback(ir)\n",
    "\n",
    "critique = Answer(\n",
    "    reasoning=\"The breakdown was good but solutions were too verbose\",\n",
    "    answer=\"correct but explained too much\",\n",
    ")\n",
    "\n",
    "output, gradient = af.call(pb_ir)((\"What is 15% of 80?\", critique))\n",
    "\n",
    "print(\"Answer:\", output.answer)\n",
    "print(\"\\nGradient (how to improve input):\")\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63fe3b",
   "metadata": {},
   "source": [
    "## 7. Batched Gradients\n",
    "\n",
    "Get improvement hints for multiple questions at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c742236",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_pb = af.batch(\n",
    "    pb_ir,\n",
    "    in_axes=(True, Answer.model_construct(reasoning=True, answer=True)),\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"What is 15% of 80?\",\n",
    "    \"How many days in a leap year?\",\n",
    "    \"What is the capital of Japan?\",\n",
    "]\n",
    "\n",
    "critiques = Answer.model_construct(\n",
    "    reasoning=[\"too verbose\", \"perfect\", \"needs more context\"],\n",
    "    answer=[\"correct\", \"correct\", \"correct\"],\n",
    ")\n",
    "\n",
    "outputs, grads = af.call(batched_pb)((questions, critiques))\n",
    "\n",
    "for i, (q, g) in enumerate(zip(questions, grads)):\n",
    "    print(f\"\\nQ{i + 1}: {q}\")\n",
    "    print(f\"Hint: {g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31110f6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **Checkpoint** each reasoning step for visibility\n",
    "2. **Collect** captures intermediate values for debugging\n",
    "3. **Pullback** provides improvement hints from output feedback\n",
    "4. **Batch** processes multiple inputs with their critiques\n",
    "\n",
    "Use this pattern for any multi-step pipeline where you need to understand _which step_ to improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "af",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
